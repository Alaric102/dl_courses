{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.252433, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.316099, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.001344, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.089407, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320099, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.080352, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172179, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.088964, Train accuracy: 0.211444, val accuracy: 0.221000\n",
      "Loss: 2.105950, Train accuracy: 0.242111, val accuracy: 0.243000\n",
      "Loss: 2.022756, Train accuracy: 0.265444, val accuracy: 0.265000\n",
      "Loss: 2.061268, Train accuracy: 0.271889, val accuracy: 0.271000\n",
      "Loss: 1.729621, Train accuracy: 0.286667, val accuracy: 0.291000\n",
      "Loss: 1.956286, Train accuracy: 0.316778, val accuracy: 0.322000\n",
      "Loss: 1.889911, Train accuracy: 0.351556, val accuracy: 0.347000\n",
      "Loss: 1.785224, Train accuracy: 0.378667, val accuracy: 0.372000\n",
      "Loss: 1.791668, Train accuracy: 0.408556, val accuracy: 0.406000\n",
      "Loss: 1.564367, Train accuracy: 0.430111, val accuracy: 0.419000\n",
      "Loss: 1.680335, Train accuracy: 0.450000, val accuracy: 0.433000\n",
      "Loss: 1.666212, Train accuracy: 0.485111, val accuracy: 0.480000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc19c43e430>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.278138, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.346800, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304661, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.403954, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153024, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226667, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.337390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293205, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251443, Train accuracy: 0.197111, val accuracy: 0.207000\n",
      "Loss: 2.161974, Train accuracy: 0.212333, val accuracy: 0.221000\n",
      "Loss: 2.162267, Train accuracy: 0.228667, val accuracy: 0.239000\n",
      "Loss: 2.069132, Train accuracy: 0.242556, val accuracy: 0.247000\n",
      "Loss: 2.136886, Train accuracy: 0.254222, val accuracy: 0.250000\n",
      "Loss: 2.051139, Train accuracy: 0.261667, val accuracy: 0.258000\n",
      "Loss: 2.180649, Train accuracy: 0.268556, val accuracy: 0.265000\n",
      "Loss: 2.122797, Train accuracy: 0.275889, val accuracy: 0.282000\n",
      "Loss: 2.123539, Train accuracy: 0.279222, val accuracy: 0.290000\n",
      "Loss: 1.965114, Train accuracy: 0.295778, val accuracy: 0.301000\n",
      "Loss: 2.036744, Train accuracy: 0.308889, val accuracy: 0.314000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc19c11f310>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.179805, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.989123, Train accuracy: 0.280222, val accuracy: 0.281000\n",
      "Loss: 2.058906, Train accuracy: 0.415667, val accuracy: 0.416000\n",
      "Loss: 1.872793, Train accuracy: 0.487444, val accuracy: 0.505000\n",
      "Loss: 2.102998, Train accuracy: 0.545778, val accuracy: 0.548000\n",
      "Loss: 1.855779, Train accuracy: 0.541444, val accuracy: 0.541000\n",
      "Loss: 1.977084, Train accuracy: 0.575222, val accuracy: 0.570000\n",
      "Loss: 1.477033, Train accuracy: 0.603111, val accuracy: 0.606000\n",
      "Loss: 1.645663, Train accuracy: 0.605333, val accuracy: 0.608000\n",
      "Loss: 1.754896, Train accuracy: 0.612333, val accuracy: 0.606000\n",
      "Loss: 1.725089, Train accuracy: 0.627778, val accuracy: 0.624000\n",
      "Loss: 1.687508, Train accuracy: 0.615222, val accuracy: 0.623000\n",
      "Loss: 1.770167, Train accuracy: 0.635667, val accuracy: 0.639000\n",
      "Loss: 1.748873, Train accuracy: 0.641778, val accuracy: 0.634000\n",
      "Loss: 1.941646, Train accuracy: 0.640222, val accuracy: 0.633000\n",
      "Loss: 1.715592, Train accuracy: 0.636444, val accuracy: 0.618000\n",
      "Loss: 1.868449, Train accuracy: 0.633556, val accuracy: 0.621000\n",
      "Loss: 1.775940, Train accuracy: 0.618667, val accuracy: 0.623000\n",
      "Loss: 1.807615, Train accuracy: 0.664444, val accuracy: 0.659000\n",
      "Loss: 1.865005, Train accuracy: 0.663556, val accuracy: 0.646000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.95)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc1c4fcdca0>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.339879, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.335874, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.329886, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.309027, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.299067, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.240735, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.278832, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.307599, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.185783, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.040308, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.759900, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.762941, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.119104, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.819810, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.743585, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943945, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.468244, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.219984, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.468250, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.606346, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937483, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.909484, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.841697, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.750139, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.389171, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.265442, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.143168, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.277707, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.036351, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.934721, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.685879, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.396895, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.856214, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.281029, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.522192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.210020, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.758974, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.736432, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.551067, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.553217, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.896327, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.958763, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.339973, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.811289, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.432478, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.149457, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.105357, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.612458, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.378738, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.449549, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.028300, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.316611, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.623720, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.777900, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.135039, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.433478, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.622142, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.264112, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.482993, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.178103, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.058584, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.538452, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.312664, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369315, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.595223, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.382773, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.364519, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.372693, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.602177, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.989621, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.645971, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.961363, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.392238, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.942749, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.206221, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.935694, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.626671, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.514531, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.733506, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.142457, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.857363, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223565, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.724819, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.323960, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.675050, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.206595, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227081, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.713930, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.190712, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.287920, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.736299, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.283754, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.993075, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.473925, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.346671, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.576790, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.689450, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.308120, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.651206, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.337932, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.409077, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.191086, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.161950, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.367172, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.488913, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.386559, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.288491, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.692739, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.107793, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.616887, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.382336, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.370985, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.209253, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.351902, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.251511, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.340175, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.274453, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.472712, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.113801, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.740432, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.434140, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.279513, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.192304, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.474337, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.335307, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.638546, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.238987, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.420691, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.237512, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.378565, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.428931, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.359646, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.140843, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.247832, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219586, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.294960, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.350469, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.480653, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.290054, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.358638, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.286535, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.492461, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.237070, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.464132, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.213591, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.273278, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.149202, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.472598, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.493875, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.220476, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.295846, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.245376, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.277211, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.011300, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 2.326049, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.347340, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 2.002511, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 1.372993, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.199551, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.552638, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.426179, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 1.353960, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.862500, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.348313, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.208718, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.294617, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.146985, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.363935, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.167331, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.022970, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0.0001)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=0.2, num_epochs=20, batch_size=3)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.156526, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.093231, Train accuracy: 0.201000, val accuracy: 0.208000\n",
      "Loss: 2.126730, Train accuracy: 0.303111, val accuracy: 0.309000\n",
      "Loss: 1.945308, Train accuracy: 0.393444, val accuracy: 0.381000\n",
      "Loss: 1.526355, Train accuracy: 0.451000, val accuracy: 0.444000\n",
      "Loss: 1.564850, Train accuracy: 0.513222, val accuracy: 0.507000\n",
      "Loss: 1.484644, Train accuracy: 0.539556, val accuracy: 0.537000\n",
      "Loss: 1.338420, Train accuracy: 0.576111, val accuracy: 0.567000\n",
      "Loss: 1.185805, Train accuracy: 0.592111, val accuracy: 0.572000\n",
      "Loss: 1.371995, Train accuracy: 0.607333, val accuracy: 0.588000\n",
      "Loss: 1.494615, Train accuracy: 0.617000, val accuracy: 0.598000\n",
      "Loss: 1.009319, Train accuracy: 0.624333, val accuracy: 0.603000\n",
      "Loss: 1.182031, Train accuracy: 0.627667, val accuracy: 0.607000\n",
      "Loss: 1.219509, Train accuracy: 0.632333, val accuracy: 0.620000\n",
      "Loss: 1.204714, Train accuracy: 0.633000, val accuracy: 0.625000\n",
      "Loss: 1.121474, Train accuracy: 0.638000, val accuracy: 0.624000\n",
      "Loss: 1.109313, Train accuracy: 0.642111, val accuracy: 0.626000\n",
      "Loss: 1.494362, Train accuracy: 0.643222, val accuracy: 0.629000\n",
      "Loss: 1.256321, Train accuracy: 0.643778, val accuracy: 0.634000\n",
      "Loss: 1.355531, Train accuracy: 0.646778, val accuracy: 0.632000\n",
      "Loss: 1.499927, Train accuracy: 0.645000, val accuracy: 0.627000\n",
      "Loss: 1.100567, Train accuracy: 0.647556, val accuracy: 0.631000\n",
      "Loss: 1.273352, Train accuracy: 0.647778, val accuracy: 0.632000\n",
      "Loss: 1.084180, Train accuracy: 0.648222, val accuracy: 0.632000\n",
      "Loss: 0.967570, Train accuracy: 0.648444, val accuracy: 0.631000\n",
      "Loss: 1.082224, Train accuracy: 0.649111, val accuracy: 0.631000\n",
      "Loss: 1.137816, Train accuracy: 0.648778, val accuracy: 0.630000\n",
      "Loss: 1.028923, Train accuracy: 0.648667, val accuracy: 0.630000\n",
      "Loss: 0.983469, Train accuracy: 0.649111, val accuracy: 0.631000\n",
      "Loss: 1.321222, Train accuracy: 0.649778, val accuracy: 0.630000\n",
      "Loss: 1.023122, Train accuracy: 0.649222, val accuracy: 0.630000\n",
      "Loss: 1.141109, Train accuracy: 0.649333, val accuracy: 0.631000\n",
      "Loss: 1.188335, Train accuracy: 0.649444, val accuracy: 0.630000\n",
      "Loss: 1.367714, Train accuracy: 0.649444, val accuracy: 0.630000\n",
      "Loss: 1.145018, Train accuracy: 0.649556, val accuracy: 0.630000\n",
      "Loss: 0.834299, Train accuracy: 0.649556, val accuracy: 0.630000\n",
      "Loss: 1.338054, Train accuracy: 0.649778, val accuracy: 0.631000\n",
      "Loss: 1.190866, Train accuracy: 0.649778, val accuracy: 0.630000\n",
      "Loss: 0.888862, Train accuracy: 0.649778, val accuracy: 0.630000\n",
      "Loss: 1.200926, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.150541, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.215984, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 0.961453, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.293401, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.938668, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.233491, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.329927, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.556775, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.002186, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 0.982780, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.218495, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 1.171556, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 0.910907, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 0.971278, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 0.947095, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.175547, Train accuracy: 0.649889, val accuracy: 0.630000\n",
      "Loss: 0.967991, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.026898, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.283079, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.133801, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.203425, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.423223, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.554404, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.135370, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.197979, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.089805, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.012407, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.247455, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.150157, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.234110, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.231654, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.058696, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.132860, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.161333, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.457904, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.084772, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.299609, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.273394, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.957057, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.163350, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.683643, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.138930, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.993656, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.146065, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.312034, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.192796, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.480774, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.271653, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.210539, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.286692, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.297057, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.910067, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.861994, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.995746, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.195721, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.209670, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.169891, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.245369, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.107298, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.462914, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.965583, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.005392, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.363450, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.034295, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.136847, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.199944, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.366445, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.074713, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.916420, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.143556, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.008553, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.089280, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.301986, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.401073, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.190182, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.255766, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.971350, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.976854, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.394399, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.243161, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.131957, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.343699, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.061163, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.238658, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.351135, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.165482, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.968216, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.060879, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.439601, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.041025, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.065576, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.196313, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.092788, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.126235, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.357855, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.219151, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.983368, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.303234, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.547233, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.204224, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.383499, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.197601, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.189171, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.281824, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.080464, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.527107, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.259846, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.306261, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.298430, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.276641, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.100489, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.082209, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.076397, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.154227, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.043012, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.081127, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.413053, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.953365, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.936442, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.473688, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.504293, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.151730, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.090743, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.048985, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.334298, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.062082, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.167210, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.943451, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.405193, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.429781, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.142965, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.146247, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.259341, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.432969, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.973360, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.928991, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.112829, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.181967, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.000293, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.237345, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.357968, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.112385, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.036819, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.961888, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.225272, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.018875, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.103531, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.332841, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.234729, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.467571, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.083491, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.274453, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.242834, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.052067, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.125411, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.983651, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.912255, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 0.734843, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.179233, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "Loss: 1.353680, Train accuracy: 0.649889, val accuracy: 0.631000\n",
      "lr: 0.021210883868369914 ; reg: 0.000223171307936186 ; hidden: 64\n",
      "Loss: 2.215189, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193857, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155326, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155372, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171856, Train accuracy: 0.217333, val accuracy: 0.223000\n",
      "Loss: 2.102747, Train accuracy: 0.252667, val accuracy: 0.254000\n",
      "Loss: 1.883235, Train accuracy: 0.264889, val accuracy: 0.266000\n",
      "Loss: 1.969235, Train accuracy: 0.278667, val accuracy: 0.275000\n",
      "Loss: 2.088419, Train accuracy: 0.284444, val accuracy: 0.290000\n",
      "Loss: 1.915287, Train accuracy: 0.298778, val accuracy: 0.306000\n",
      "Loss: 2.039954, Train accuracy: 0.315333, val accuracy: 0.323000\n",
      "Loss: 2.157154, Train accuracy: 0.335889, val accuracy: 0.336000\n",
      "Loss: 2.014074, Train accuracy: 0.346778, val accuracy: 0.339000\n",
      "Loss: 2.036723, Train accuracy: 0.353556, val accuracy: 0.350000\n",
      "Loss: 1.851462, Train accuracy: 0.360000, val accuracy: 0.352000\n",
      "Loss: 2.081430, Train accuracy: 0.370778, val accuracy: 0.364000\n",
      "Loss: 1.952644, Train accuracy: 0.374444, val accuracy: 0.371000\n",
      "Loss: 1.822477, Train accuracy: 0.379333, val accuracy: 0.376000\n",
      "Loss: 1.734269, Train accuracy: 0.383000, val accuracy: 0.379000\n",
      "Loss: 2.000141, Train accuracy: 0.386444, val accuracy: 0.383000\n",
      "Loss: 1.865235, Train accuracy: 0.389333, val accuracy: 0.381000\n",
      "Loss: 2.004579, Train accuracy: 0.392778, val accuracy: 0.385000\n",
      "Loss: 1.885167, Train accuracy: 0.394889, val accuracy: 0.387000\n",
      "Loss: 1.992144, Train accuracy: 0.395444, val accuracy: 0.387000\n",
      "Loss: 1.950668, Train accuracy: 0.397333, val accuracy: 0.389000\n",
      "Loss: 1.865704, Train accuracy: 0.398000, val accuracy: 0.392000\n",
      "Loss: 1.699290, Train accuracy: 0.399667, val accuracy: 0.391000\n",
      "Loss: 1.706466, Train accuracy: 0.399444, val accuracy: 0.392000\n",
      "Loss: 1.882326, Train accuracy: 0.401000, val accuracy: 0.392000\n",
      "Loss: 1.962008, Train accuracy: 0.401556, val accuracy: 0.392000\n",
      "Loss: 1.975372, Train accuracy: 0.402556, val accuracy: 0.393000\n",
      "Loss: 1.733850, Train accuracy: 0.403222, val accuracy: 0.393000\n",
      "Loss: 2.194345, Train accuracy: 0.403444, val accuracy: 0.393000\n",
      "Loss: 1.834399, Train accuracy: 0.403444, val accuracy: 0.394000\n",
      "Loss: 1.796742, Train accuracy: 0.403889, val accuracy: 0.395000\n",
      "Loss: 1.778103, Train accuracy: 0.403667, val accuracy: 0.393000\n",
      "Loss: 1.989221, Train accuracy: 0.404111, val accuracy: 0.394000\n",
      "Loss: 1.822149, Train accuracy: 0.404111, val accuracy: 0.393000\n",
      "Loss: 1.855147, Train accuracy: 0.404000, val accuracy: 0.393000\n",
      "Loss: 1.839324, Train accuracy: 0.404000, val accuracy: 0.394000\n",
      "Loss: 1.674204, Train accuracy: 0.404111, val accuracy: 0.394000\n",
      "Loss: 1.680219, Train accuracy: 0.404333, val accuracy: 0.393000\n",
      "Loss: 1.911962, Train accuracy: 0.404222, val accuracy: 0.394000\n",
      "Loss: 1.796905, Train accuracy: 0.404333, val accuracy: 0.394000\n",
      "Loss: 1.710866, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 2.000909, Train accuracy: 0.404444, val accuracy: 0.393000\n",
      "Loss: 1.883262, Train accuracy: 0.404444, val accuracy: 0.393000\n",
      "Loss: 1.629178, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.907088, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.706516, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.929423, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.921143, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.742465, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.847377, Train accuracy: 0.404444, val accuracy: 0.394000\n",
      "Loss: 1.608151, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.783834, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.820807, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.950365, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.948419, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.747797, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.903254, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.879108, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.620793, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.863646, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.675596, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.775686, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.983412, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.921087, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.882086, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.409530, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.599663, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.083524, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.659927, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.898629, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.954359, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.780442, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.671652, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.905911, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.887555, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.939317, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.866712, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.829459, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.886351, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.809409, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.868409, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.936044, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.948831, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.734051, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.626309, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.794899, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.851779, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.636896, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.984437, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.753030, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.777889, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.527473, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.862947, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.898561, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.907965, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.869403, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.833919, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.682408, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.835069, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.944484, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.717695, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.003124, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.694619, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.920787, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.718647, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.700902, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.934868, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.909080, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.713492, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.812142, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.746754, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.920243, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.771806, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.930470, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.986981, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.941779, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.789134, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.845184, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.939615, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.821361, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.884197, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.106986, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.820934, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.551926, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.740763, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.072133, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.837166, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.750494, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.870126, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.594767, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.871701, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.778019, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.919272, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.616825, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.707566, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.738429, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.854686, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.718169, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.843309, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.006017, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.931987, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.068564, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.886745, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.002709, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.888648, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.694201, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.900682, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.890443, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.747444, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.797922, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.657447, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.829401, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.745032, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.914907, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.816244, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.902398, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.904520, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.902968, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.075633, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.755989, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.944764, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.884570, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.982661, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.879963, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.694119, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.922952, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.705429, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.892115, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.903878, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.675498, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.832257, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.707839, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.654120, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.653982, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.718897, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.710207, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.783581, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.024473, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.807886, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.886420, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.867825, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.867226, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.721812, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.005889, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.784534, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.682885, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.742406, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.991627, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.742304, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.712167, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.864466, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.843638, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.698231, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.061378, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.806536, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 1.941312, Train accuracy: 0.404556, val accuracy: 0.394000\n",
      "Loss: 2.074828, Train accuracy: 0.270778, val accuracy: 0.282000\n",
      "Loss: 1.730679, Train accuracy: 0.519000, val accuracy: 0.513000\n",
      "Loss: 1.355933, Train accuracy: 0.584222, val accuracy: 0.591000\n",
      "Loss: 1.275764, Train accuracy: 0.629000, val accuracy: 0.600000\n",
      "Loss: 0.814475, Train accuracy: 0.699444, val accuracy: 0.653000\n",
      "Loss: 0.986440, Train accuracy: 0.719556, val accuracy: 0.669000\n",
      "Loss: 0.975966, Train accuracy: 0.748556, val accuracy: 0.701000\n",
      "Loss: 0.872861, Train accuracy: 0.743333, val accuracy: 0.701000\n",
      "Loss: 0.719666, Train accuracy: 0.772778, val accuracy: 0.709000\n",
      "Loss: 0.680265, Train accuracy: 0.781222, val accuracy: 0.719000\n",
      "Loss: 0.565557, Train accuracy: 0.799222, val accuracy: 0.732000\n",
      "Loss: 0.744472, Train accuracy: 0.795222, val accuracy: 0.714000\n",
      "Loss: 0.936203, Train accuracy: 0.809556, val accuracy: 0.733000\n",
      "Loss: 0.581188, Train accuracy: 0.815333, val accuracy: 0.724000\n",
      "Loss: 0.642970, Train accuracy: 0.824778, val accuracy: 0.738000\n",
      "Loss: 0.575719, Train accuracy: 0.829444, val accuracy: 0.734000\n",
      "Loss: 0.658574, Train accuracy: 0.828556, val accuracy: 0.734000\n",
      "Loss: 0.865363, Train accuracy: 0.832889, val accuracy: 0.740000\n",
      "Loss: 0.928910, Train accuracy: 0.832889, val accuracy: 0.735000\n",
      "Loss: 0.726969, Train accuracy: 0.837000, val accuracy: 0.738000\n",
      "Loss: 0.639626, Train accuracy: 0.837556, val accuracy: 0.737000\n",
      "Loss: 0.627883, Train accuracy: 0.836444, val accuracy: 0.737000\n",
      "Loss: 0.496491, Train accuracy: 0.839000, val accuracy: 0.740000\n",
      "Loss: 0.660857, Train accuracy: 0.842556, val accuracy: 0.744000\n",
      "Loss: 0.670993, Train accuracy: 0.843000, val accuracy: 0.742000\n",
      "Loss: 0.779168, Train accuracy: 0.843111, val accuracy: 0.740000\n",
      "Loss: 0.824162, Train accuracy: 0.842667, val accuracy: 0.739000\n",
      "Loss: 0.406912, Train accuracy: 0.841667, val accuracy: 0.742000\n",
      "Loss: 0.441660, Train accuracy: 0.843444, val accuracy: 0.742000\n",
      "Loss: 0.481793, Train accuracy: 0.844000, val accuracy: 0.740000\n",
      "Loss: 0.463824, Train accuracy: 0.843111, val accuracy: 0.742000\n",
      "Loss: 0.613029, Train accuracy: 0.843222, val accuracy: 0.742000\n",
      "Loss: 0.796325, Train accuracy: 0.844222, val accuracy: 0.742000\n",
      "Loss: 0.672700, Train accuracy: 0.845000, val accuracy: 0.744000\n",
      "Loss: 0.524660, Train accuracy: 0.844111, val accuracy: 0.744000\n",
      "Loss: 0.923338, Train accuracy: 0.844444, val accuracy: 0.744000\n",
      "Loss: 0.791930, Train accuracy: 0.844111, val accuracy: 0.743000\n",
      "Loss: 0.513641, Train accuracy: 0.844333, val accuracy: 0.744000\n",
      "Loss: 0.558440, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.560396, Train accuracy: 0.844778, val accuracy: 0.744000\n",
      "Loss: 0.577454, Train accuracy: 0.844556, val accuracy: 0.744000\n",
      "Loss: 0.414820, Train accuracy: 0.844556, val accuracy: 0.743000\n",
      "Loss: 0.652294, Train accuracy: 0.844556, val accuracy: 0.743000\n",
      "Loss: 0.711489, Train accuracy: 0.844778, val accuracy: 0.744000\n",
      "Loss: 0.850977, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.624481, Train accuracy: 0.844667, val accuracy: 0.744000\n",
      "Loss: 0.509412, Train accuracy: 0.844444, val accuracy: 0.744000\n",
      "Loss: 0.464805, Train accuracy: 0.844556, val accuracy: 0.743000\n",
      "Loss: 0.700028, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.572272, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.545999, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.289620, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.453499, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.483610, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.564992, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.707669, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.697994, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.593691, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.480576, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.512719, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.521186, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.446100, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.744218, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.712432, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.493468, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.518080, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.662289, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.620849, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.779698, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.563664, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.433881, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.329395, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.707217, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.516654, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.465928, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.670731, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.401200, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.610391, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.411238, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.596401, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.688588, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.628208, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.560598, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.674781, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.384106, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.573439, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.464470, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.649176, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.622069, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.668152, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.498258, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.718799, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.416438, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.484017, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.644874, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.584696, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.521232, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.811336, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.707682, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.573514, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.661351, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.646403, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.515235, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.587941, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.748561, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.465907, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.475816, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.512054, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.641577, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.426990, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.560950, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.693062, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.713249, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.439144, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.708534, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.571643, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.321160, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.481308, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.340785, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.588052, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.658818, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.606511, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.590429, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.648534, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.506045, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.691030, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.555071, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.597872, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.530397, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.493462, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.544689, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.546448, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.482541, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.392428, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.531570, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.441500, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.635860, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.368856, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.523757, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.670225, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.495656, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.657355, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.677303, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.868708, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.666054, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.497877, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.620925, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.584134, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.605491, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.256418, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.508850, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.607693, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.669405, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.614538, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.689227, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.567806, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.591158, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.426300, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.637949, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.782032, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.478178, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.550631, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.641479, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.560404, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.438023, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.711480, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.561909, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.635987, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.474048, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.573694, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.413209, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.785327, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.513950, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.663132, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.405921, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.332714, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.486559, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 1.046051, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.488462, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.868506, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.624228, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.563622, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.498893, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.401261, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.637329, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.437011, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.715448, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.737501, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.748589, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.732765, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.606793, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.519037, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.714639, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.669639, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.535772, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 1.133583, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.532794, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.398831, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.517963, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "Loss: 0.642484, Train accuracy: 0.844333, val accuracy: 0.743000\n",
      "lr: 0.07574675365399446 ; reg: 0.00012616977590721313 ; hidden: 44\n",
      "Loss: 2.270723, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229013, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.147090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217230, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276052, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263305, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.196331, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182490, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287584, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286787, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125451, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.156819, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180087, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256073, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256346, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236099, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297669, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266566, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270836, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218240, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219338, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201605, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254245, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321045, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174844, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.206777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229338, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237339, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239540, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247613, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300686, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263025, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227079, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235041, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224889, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237797, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277833, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.165350, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237865, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231851, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181713, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207646, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.355637, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253741, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289082, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271144, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242480, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231000, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168666, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155334, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259451, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.185695, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251658, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186392, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202007, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226137, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213641, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229375, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.196946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224563, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.114241, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192597, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216215, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297478, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207074, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293892, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160641, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.199352, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234378, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263144, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267882, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244585, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257745, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245503, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230895, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228652, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245934, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264891, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177291, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277765, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310228, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283960, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151789, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286795, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142653, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239957, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251437, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239839, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205765, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192892, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213914, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.322552, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262272, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280813, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213260, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261814, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263585, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178314, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214193, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238461, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243666, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263432, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292108, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265384, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.113933, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184812, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231227, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221785, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312158, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.211135, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213920, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.199669, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261841, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.083394, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.336044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.119427, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160746, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258607, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275684, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284109, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252049, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.342837, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227737, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293335, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187400, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177434, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229313, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.148502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257608, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246123, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219507, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223353, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210091, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255268, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.340869, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301910, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.196271, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218528, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231340, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265632, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.132828, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292153, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215796, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182105, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214643, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174097, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202736, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241808, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230525, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279357, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226717, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215557, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230828, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277802, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.128486, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205961, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267697, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244352, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.019573, Train accuracy: 0.206778, val accuracy: 0.227000\n",
      "Loss: 1.877767, Train accuracy: 0.340889, val accuracy: 0.329000\n",
      "Loss: 1.556266, Train accuracy: 0.440444, val accuracy: 0.433000\n",
      "Loss: 1.722485, Train accuracy: 0.550222, val accuracy: 0.535000\n",
      "Loss: 1.115606, Train accuracy: 0.588778, val accuracy: 0.566000\n",
      "Loss: 1.013221, Train accuracy: 0.632000, val accuracy: 0.625000\n",
      "Loss: 1.178378, Train accuracy: 0.671444, val accuracy: 0.662000\n",
      "Loss: 1.406737, Train accuracy: 0.691889, val accuracy: 0.662000\n",
      "Loss: 1.193819, Train accuracy: 0.694111, val accuracy: 0.676000\n",
      "Loss: 1.000432, Train accuracy: 0.698333, val accuracy: 0.662000\n",
      "Loss: 1.141964, Train accuracy: 0.722222, val accuracy: 0.688000\n",
      "Loss: 1.099703, Train accuracy: 0.729333, val accuracy: 0.704000\n",
      "Loss: 0.949536, Train accuracy: 0.743222, val accuracy: 0.710000\n",
      "Loss: 0.705802, Train accuracy: 0.743444, val accuracy: 0.702000\n",
      "Loss: 1.055764, Train accuracy: 0.746889, val accuracy: 0.719000\n",
      "Loss: 0.823411, Train accuracy: 0.757556, val accuracy: 0.712000\n",
      "Loss: 1.052391, Train accuracy: 0.747778, val accuracy: 0.705000\n",
      "Loss: 0.622965, Train accuracy: 0.767000, val accuracy: 0.714000\n",
      "Loss: 0.632408, Train accuracy: 0.770222, val accuracy: 0.717000\n",
      "Loss: 0.975366, Train accuracy: 0.780556, val accuracy: 0.717000\n",
      "Loss: 0.690456, Train accuracy: 0.784444, val accuracy: 0.723000\n",
      "Loss: 0.727380, Train accuracy: 0.783667, val accuracy: 0.721000\n",
      "Loss: 0.666185, Train accuracy: 0.789000, val accuracy: 0.720000\n",
      "Loss: 0.643036, Train accuracy: 0.792889, val accuracy: 0.734000\n",
      "Loss: 0.725286, Train accuracy: 0.796222, val accuracy: 0.730000\n",
      "Loss: 0.958478, Train accuracy: 0.795889, val accuracy: 0.725000\n",
      "Loss: 0.706164, Train accuracy: 0.801333, val accuracy: 0.726000\n",
      "Loss: 0.758840, Train accuracy: 0.802889, val accuracy: 0.727000\n",
      "Loss: 0.780213, Train accuracy: 0.801556, val accuracy: 0.741000\n",
      "Loss: 0.732222, Train accuracy: 0.804111, val accuracy: 0.736000\n",
      "Loss: 0.862861, Train accuracy: 0.806222, val accuracy: 0.738000\n",
      "Loss: 0.787756, Train accuracy: 0.806111, val accuracy: 0.726000\n",
      "Loss: 0.621004, Train accuracy: 0.808556, val accuracy: 0.734000\n",
      "Loss: 0.983388, Train accuracy: 0.812556, val accuracy: 0.732000\n",
      "Loss: 0.596425, Train accuracy: 0.812222, val accuracy: 0.731000\n",
      "Loss: 0.758284, Train accuracy: 0.814778, val accuracy: 0.729000\n",
      "Loss: 0.794938, Train accuracy: 0.813444, val accuracy: 0.734000\n",
      "Loss: 0.856926, Train accuracy: 0.814333, val accuracy: 0.737000\n",
      "Loss: 0.857861, Train accuracy: 0.815333, val accuracy: 0.731000\n",
      "Loss: 0.856962, Train accuracy: 0.817222, val accuracy: 0.740000\n",
      "Loss: 0.902942, Train accuracy: 0.818556, val accuracy: 0.729000\n",
      "Loss: 0.756185, Train accuracy: 0.820778, val accuracy: 0.737000\n",
      "Loss: 0.629221, Train accuracy: 0.821889, val accuracy: 0.739000\n",
      "Loss: 1.059366, Train accuracy: 0.823000, val accuracy: 0.733000\n",
      "Loss: 0.723671, Train accuracy: 0.821000, val accuracy: 0.743000\n",
      "Loss: 0.661472, Train accuracy: 0.823778, val accuracy: 0.737000\n",
      "Loss: 0.439301, Train accuracy: 0.823667, val accuracy: 0.739000\n",
      "Loss: 0.544570, Train accuracy: 0.825444, val accuracy: 0.732000\n",
      "Loss: 0.652507, Train accuracy: 0.827333, val accuracy: 0.737000\n",
      "Loss: 0.671836, Train accuracy: 0.826111, val accuracy: 0.733000\n",
      "Loss: 0.630161, Train accuracy: 0.826333, val accuracy: 0.738000\n",
      "Loss: 0.709625, Train accuracy: 0.826667, val accuracy: 0.736000\n",
      "Loss: 0.833246, Train accuracy: 0.827333, val accuracy: 0.739000\n",
      "Loss: 0.506343, Train accuracy: 0.828111, val accuracy: 0.740000\n",
      "Loss: 0.811884, Train accuracy: 0.828778, val accuracy: 0.733000\n",
      "Loss: 0.700357, Train accuracy: 0.827778, val accuracy: 0.729000\n",
      "Loss: 0.697315, Train accuracy: 0.829000, val accuracy: 0.738000\n",
      "Loss: 0.645643, Train accuracy: 0.827333, val accuracy: 0.738000\n",
      "Loss: 0.547403, Train accuracy: 0.827000, val accuracy: 0.734000\n",
      "Loss: 0.866934, Train accuracy: 0.829889, val accuracy: 0.741000\n",
      "Loss: 0.565968, Train accuracy: 0.830222, val accuracy: 0.737000\n",
      "Loss: 0.595666, Train accuracy: 0.828778, val accuracy: 0.740000\n",
      "Loss: 0.764671, Train accuracy: 0.829889, val accuracy: 0.743000\n",
      "Loss: 0.504766, Train accuracy: 0.830333, val accuracy: 0.740000\n",
      "Loss: 0.587025, Train accuracy: 0.830000, val accuracy: 0.738000\n",
      "Loss: 0.654308, Train accuracy: 0.829000, val accuracy: 0.740000\n",
      "Loss: 0.740629, Train accuracy: 0.831111, val accuracy: 0.735000\n",
      "Loss: 0.687443, Train accuracy: 0.830556, val accuracy: 0.739000\n",
      "Loss: 0.438567, Train accuracy: 0.831000, val accuracy: 0.738000\n",
      "Loss: 0.656082, Train accuracy: 0.829889, val accuracy: 0.738000\n",
      "Loss: 0.790503, Train accuracy: 0.830889, val accuracy: 0.738000\n",
      "Loss: 0.578012, Train accuracy: 0.829000, val accuracy: 0.737000\n",
      "Loss: 0.746369, Train accuracy: 0.830778, val accuracy: 0.736000\n",
      "Loss: 0.866028, Train accuracy: 0.831556, val accuracy: 0.740000\n",
      "Loss: 0.632656, Train accuracy: 0.831667, val accuracy: 0.740000\n",
      "Loss: 0.690552, Train accuracy: 0.831111, val accuracy: 0.735000\n",
      "Loss: 0.658753, Train accuracy: 0.830444, val accuracy: 0.738000\n",
      "Loss: 0.825279, Train accuracy: 0.831333, val accuracy: 0.737000\n",
      "Loss: 0.514426, Train accuracy: 0.831444, val accuracy: 0.737000\n",
      "Loss: 0.777873, Train accuracy: 0.831667, val accuracy: 0.737000\n",
      "Loss: 0.590159, Train accuracy: 0.832111, val accuracy: 0.739000\n",
      "Loss: 0.599812, Train accuracy: 0.831444, val accuracy: 0.738000\n",
      "Loss: 0.514463, Train accuracy: 0.832333, val accuracy: 0.737000\n",
      "Loss: 0.725211, Train accuracy: 0.832000, val accuracy: 0.738000\n",
      "Loss: 0.859659, Train accuracy: 0.832222, val accuracy: 0.739000\n",
      "Loss: 0.589465, Train accuracy: 0.832111, val accuracy: 0.738000\n",
      "Loss: 0.581065, Train accuracy: 0.832333, val accuracy: 0.738000\n",
      "Loss: 0.783494, Train accuracy: 0.832000, val accuracy: 0.738000\n",
      "Loss: 0.633234, Train accuracy: 0.832111, val accuracy: 0.738000\n",
      "Loss: 0.843142, Train accuracy: 0.832111, val accuracy: 0.736000\n",
      "Loss: 0.630532, Train accuracy: 0.832556, val accuracy: 0.738000\n",
      "Loss: 0.597828, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 0.739450, Train accuracy: 0.832333, val accuracy: 0.737000\n",
      "Loss: 0.443720, Train accuracy: 0.832556, val accuracy: 0.736000\n",
      "Loss: 0.661267, Train accuracy: 0.832444, val accuracy: 0.736000\n",
      "Loss: 0.744243, Train accuracy: 0.832778, val accuracy: 0.736000\n",
      "Loss: 0.867300, Train accuracy: 0.832667, val accuracy: 0.737000\n",
      "Loss: 0.557568, Train accuracy: 0.832778, val accuracy: 0.737000\n",
      "Loss: 0.793006, Train accuracy: 0.832556, val accuracy: 0.737000\n",
      "Loss: 0.722137, Train accuracy: 0.832667, val accuracy: 0.737000\n",
      "Loss: 0.756624, Train accuracy: 0.832222, val accuracy: 0.738000\n",
      "Loss: 0.642443, Train accuracy: 0.832333, val accuracy: 0.737000\n",
      "Loss: 0.937111, Train accuracy: 0.832556, val accuracy: 0.738000\n",
      "Loss: 0.675050, Train accuracy: 0.832556, val accuracy: 0.738000\n",
      "Loss: 0.598747, Train accuracy: 0.832444, val accuracy: 0.738000\n",
      "Loss: 0.439970, Train accuracy: 0.832444, val accuracy: 0.738000\n",
      "Loss: 1.016536, Train accuracy: 0.832556, val accuracy: 0.738000\n",
      "Loss: 0.427718, Train accuracy: 0.832556, val accuracy: 0.738000\n",
      "Loss: 0.432620, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 0.967124, Train accuracy: 0.832778, val accuracy: 0.737000\n",
      "Loss: 0.636419, Train accuracy: 0.832556, val accuracy: 0.738000\n",
      "Loss: 0.635851, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.584506, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 1.012796, Train accuracy: 0.832444, val accuracy: 0.737000\n",
      "Loss: 0.560770, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 1.068308, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.704626, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 0.624956, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.482784, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.640025, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.655652, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.579951, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.696930, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.913476, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.530842, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 0.620569, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.416695, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 0.732001, Train accuracy: 0.832667, val accuracy: 0.738000\n",
      "Loss: 0.679404, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.408446, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.565692, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.663249, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.671550, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.520700, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.497328, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.602041, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.638910, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.681350, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.686440, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.667756, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.552644, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.718382, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.638599, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.543891, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.756234, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.690465, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.488198, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.657081, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.779163, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.473843, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.485498, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.794312, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.658327, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.847775, Train accuracy: 0.833000, val accuracy: 0.738000\n",
      "Loss: 0.855345, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.509981, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.750144, Train accuracy: 0.832889, val accuracy: 0.738000\n",
      "Loss: 0.551977, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.877575, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.583808, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.746297, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.993960, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.915305, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.462033, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.542207, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.383169, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.637548, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.725016, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.609162, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.633095, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.586511, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.757101, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.750799, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.428428, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.775592, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.665234, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.698608, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.840786, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.948999, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.539990, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.775515, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.527280, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.961870, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.570900, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.710029, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.600734, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.558694, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.772293, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.679696, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.494934, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.579047, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.694942, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.515927, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.708559, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.589007, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.625848, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.688495, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.506565, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 0.839257, Train accuracy: 0.832778, val accuracy: 0.738000\n",
      "Loss: 2.247334, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249143, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174841, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168867, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.100617, Train accuracy: 0.220333, val accuracy: 0.226000\n",
      "Loss: 2.069583, Train accuracy: 0.238778, val accuracy: 0.241000\n",
      "Loss: 2.096183, Train accuracy: 0.257222, val accuracy: 0.255000\n",
      "Loss: 2.070773, Train accuracy: 0.260111, val accuracy: 0.255000\n",
      "Loss: 2.118264, Train accuracy: 0.268556, val accuracy: 0.267000\n",
      "Loss: 1.999687, Train accuracy: 0.274111, val accuracy: 0.274000\n",
      "Loss: 2.126890, Train accuracy: 0.275333, val accuracy: 0.275000\n",
      "Loss: 2.112178, Train accuracy: 0.281444, val accuracy: 0.285000\n",
      "Loss: 2.057867, Train accuracy: 0.281333, val accuracy: 0.284000\n",
      "Loss: 1.987196, Train accuracy: 0.286889, val accuracy: 0.294000\n",
      "Loss: 2.110134, Train accuracy: 0.291111, val accuracy: 0.295000\n",
      "Loss: 1.983666, Train accuracy: 0.291889, val accuracy: 0.298000\n",
      "Loss: 2.160207, Train accuracy: 0.293889, val accuracy: 0.298000\n",
      "Loss: 2.110409, Train accuracy: 0.294667, val accuracy: 0.301000\n",
      "Loss: 1.893663, Train accuracy: 0.296000, val accuracy: 0.301000\n",
      "Loss: 2.013947, Train accuracy: 0.297222, val accuracy: 0.300000\n",
      "Loss: 2.187335, Train accuracy: 0.297444, val accuracy: 0.302000\n",
      "Loss: 1.943331, Train accuracy: 0.298222, val accuracy: 0.303000\n",
      "Loss: 2.124341, Train accuracy: 0.298889, val accuracy: 0.304000\n",
      "Loss: 2.165990, Train accuracy: 0.299444, val accuracy: 0.305000\n",
      "Loss: 2.029306, Train accuracy: 0.299778, val accuracy: 0.305000\n",
      "Loss: 1.902656, Train accuracy: 0.299889, val accuracy: 0.305000\n",
      "Loss: 2.094006, Train accuracy: 0.299889, val accuracy: 0.305000\n",
      "Loss: 2.056988, Train accuracy: 0.300556, val accuracy: 0.305000\n",
      "Loss: 2.037133, Train accuracy: 0.300444, val accuracy: 0.306000\n",
      "Loss: 2.262158, Train accuracy: 0.300556, val accuracy: 0.306000\n",
      "Loss: 1.931257, Train accuracy: 0.300667, val accuracy: 0.306000\n",
      "Loss: 1.931956, Train accuracy: 0.300778, val accuracy: 0.306000\n",
      "Loss: 1.932061, Train accuracy: 0.300667, val accuracy: 0.306000\n",
      "Loss: 2.027145, Train accuracy: 0.300889, val accuracy: 0.306000\n",
      "Loss: 1.962077, Train accuracy: 0.300889, val accuracy: 0.306000\n",
      "Loss: 1.914814, Train accuracy: 0.301000, val accuracy: 0.306000\n",
      "Loss: 2.065591, Train accuracy: 0.301000, val accuracy: 0.306000\n",
      "Loss: 1.962547, Train accuracy: 0.301111, val accuracy: 0.306000\n",
      "Loss: 2.022033, Train accuracy: 0.301111, val accuracy: 0.306000\n",
      "Loss: 1.891803, Train accuracy: 0.301222, val accuracy: 0.306000\n",
      "Loss: 1.827900, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.078433, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.282914, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.048481, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.900564, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.034352, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.029915, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.881816, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.113116, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.965456, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.807768, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.969783, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.866771, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.044236, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.071057, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.255692, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.739122, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.915899, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.058890, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.104122, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.075093, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.904459, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.929686, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.014253, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.097945, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.967483, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.054089, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.001735, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.007556, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.082146, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.100896, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.002194, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.044934, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.054818, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.819939, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.012843, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.138067, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.106302, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.149514, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.975377, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.977882, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.069838, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.918984, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.191031, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.973130, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.160056, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.085685, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.080816, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.035276, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.785845, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.877556, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.136621, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.053833, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.063561, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.187175, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.014046, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.985224, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.136526, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.087116, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.046948, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.096478, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.010145, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.950348, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.182135, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.022982, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.060583, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.109525, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.194613, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.025743, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.901126, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.176148, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.908509, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.961331, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.888243, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.859978, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.907801, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.016859, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.078947, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.996148, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.130504, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.903469, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.097958, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.113425, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.052097, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.997925, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.005052, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.048051, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.049593, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.941562, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.048635, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.917605, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.971307, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.191093, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.748960, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.072015, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.831044, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.150809, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.055635, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.089564, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.976153, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.152994, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.122644, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.147989, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.782212, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.015063, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.892339, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.092222, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.094204, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.164188, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.940629, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.077896, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.194034, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.002005, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.071146, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.044644, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.963759, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.887659, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.917045, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.058086, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.933187, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.034587, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.847777, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.067477, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.940214, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.016934, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.011750, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.032943, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.933375, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.960394, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.991024, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.133689, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.901360, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.026217, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.941681, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.930194, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.116013, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.872733, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.049658, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.023271, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.169068, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.060923, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.951748, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.046330, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.111501, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.043321, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.945219, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.064673, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.914457, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.042049, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.041284, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.826801, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.261185, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.927695, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.123467, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.997278, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.132265, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.041570, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.716846, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.894773, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 1.871875, Train accuracy: 0.301333, val accuracy: 0.306000\n",
      "Loss: 2.229824, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154301, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298050, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171681, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238420, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.351557, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155532, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.185256, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213159, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170966, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188678, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250298, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155113, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.136983, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.105458, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229530, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218945, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214705, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152120, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202970, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.135490, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247611, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162591, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.140094, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265418, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.085414, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225633, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209651, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.075238, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272958, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312267, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.141525, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183456, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216295, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180387, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.007125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282838, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172395, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.998341, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223814, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.164071, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.344373, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.147728, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.044719, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192526, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.116365, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180568, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289312, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.088788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190088, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.337641, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223857, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142403, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.337005, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161294, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264196, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.133503, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.163254, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.143935, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238327, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179222, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280956, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153936, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138749, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.156788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.085132, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.114323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.997578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253239, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.206769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.163277, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225937, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173679, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252163, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192645, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249702, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.189980, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.090172, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230758, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.048871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170681, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219809, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.169327, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.163798, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.063934, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231977, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.130150, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.065395, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179852, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174573, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308866, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.354992, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175626, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.099831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186559, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191145, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266431, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.119508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.041165, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175678, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236285, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.156823, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192018, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.164453, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265296, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.167627, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.141293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287483, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.149460, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.141661, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305868, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.141209, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198987, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.129008, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145146, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.079412, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201665, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.087842, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267747, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201655, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.316059, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138052, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180197, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262579, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.146470, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232100, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.100830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202453, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168893, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265035, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236443, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253825, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.126125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288509, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178857, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277222, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208318, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.117466, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.077443, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.067527, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176002, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.165971, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.137726, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.189629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202188, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225543, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209068, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.134058, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.127048, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256607, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.170251, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.066047, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181763, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209893, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225236, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175027, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.144183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291052, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155773, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281252, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215358, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245570, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.033224, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314989, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.079589, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288300, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179926, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244253, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271827, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267135, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.090833, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.363808, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.149840, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.117825, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266900, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195091, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.147155, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.110408, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.087516, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203975, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.070465, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289415, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191583, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259281, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.120938, Train accuracy: 0.199222, val accuracy: 0.208000\n",
      "Loss: 2.112771, Train accuracy: 0.203222, val accuracy: 0.210000\n",
      "Loss: 2.308690, Train accuracy: 0.206778, val accuracy: 0.213000\n",
      "Loss: 2.114801, Train accuracy: 0.209333, val accuracy: 0.218000\n",
      "Loss: 2.048322, Train accuracy: 0.212222, val accuracy: 0.219000\n",
      "Loss: 2.321759, Train accuracy: 0.215333, val accuracy: 0.220000\n",
      "Loss: 2.004344, Train accuracy: 0.218444, val accuracy: 0.222000\n",
      "Loss: 2.141996, Train accuracy: 0.220333, val accuracy: 0.225000\n",
      "Loss: 2.182468, Train accuracy: 0.222667, val accuracy: 0.227000\n",
      "Loss: 2.212333, Train accuracy: 0.225889, val accuracy: 0.230000\n",
      "Loss: 2.135615, Train accuracy: 0.227000, val accuracy: 0.230000\n",
      "Loss: 2.061899, Train accuracy: 0.230111, val accuracy: 0.231000\n",
      "Loss: 2.109999, Train accuracy: 0.230667, val accuracy: 0.234000\n",
      "Loss: 2.008028, Train accuracy: 0.231222, val accuracy: 0.237000\n",
      "Loss: 2.161206, Train accuracy: 0.231778, val accuracy: 0.238000\n",
      "Loss: 2.198818, Train accuracy: 0.233556, val accuracy: 0.239000\n",
      "Loss: 2.186649, Train accuracy: 0.234778, val accuracy: 0.242000\n",
      "Loss: 2.159896, Train accuracy: 0.235556, val accuracy: 0.242000\n",
      "Loss: 2.236111, Train accuracy: 0.236222, val accuracy: 0.243000\n",
      "Loss: 1.943577, Train accuracy: 0.237000, val accuracy: 0.245000\n",
      "Loss: 2.076692, Train accuracy: 0.237778, val accuracy: 0.242000\n",
      "Loss: 2.274197, Train accuracy: 0.238667, val accuracy: 0.243000\n",
      "Loss: 2.112198, Train accuracy: 0.239333, val accuracy: 0.243000\n",
      "Loss: 2.079889, Train accuracy: 0.239778, val accuracy: 0.243000\n",
      "Loss: 2.094767, Train accuracy: 0.240222, val accuracy: 0.244000\n",
      "Loss: 2.112122, Train accuracy: 0.240667, val accuracy: 0.245000\n",
      "Loss: 2.238481, Train accuracy: 0.241111, val accuracy: 0.245000\n",
      "Loss: 1.908169, Train accuracy: 0.241667, val accuracy: 0.246000\n",
      "Loss: 2.107854, Train accuracy: 0.241556, val accuracy: 0.246000\n",
      "Loss: 2.227961, Train accuracy: 0.242111, val accuracy: 0.246000\n",
      "Loss: 2.160959, Train accuracy: 0.242444, val accuracy: 0.246000\n",
      "Loss: 2.181882, Train accuracy: 0.242667, val accuracy: 0.246000\n",
      "Loss: 2.167679, Train accuracy: 0.242889, val accuracy: 0.246000\n",
      "Loss: 2.013429, Train accuracy: 0.243111, val accuracy: 0.246000\n",
      "Loss: 2.148914, Train accuracy: 0.243000, val accuracy: 0.247000\n",
      "Loss: 2.054652, Train accuracy: 0.243111, val accuracy: 0.248000\n",
      "Loss: 2.220666, Train accuracy: 0.243333, val accuracy: 0.248000\n",
      "Loss: 2.085006, Train accuracy: 0.243333, val accuracy: 0.248000\n",
      "Loss: 1.916047, Train accuracy: 0.243333, val accuracy: 0.248000\n",
      "Loss: 2.115359, Train accuracy: 0.243667, val accuracy: 0.248000\n",
      "Loss: 2.133379, Train accuracy: 0.243778, val accuracy: 0.248000\n",
      "Loss: 2.134711, Train accuracy: 0.244000, val accuracy: 0.249000\n",
      "Loss: 2.201330, Train accuracy: 0.244000, val accuracy: 0.249000\n",
      "Loss: 2.069185, Train accuracy: 0.244000, val accuracy: 0.249000\n",
      "Loss: 2.176163, Train accuracy: 0.244000, val accuracy: 0.249000\n",
      "Loss: 2.137008, Train accuracy: 0.244000, val accuracy: 0.249000\n",
      "Loss: 2.227995, Train accuracy: 0.244111, val accuracy: 0.249000\n",
      "Loss: 2.078963, Train accuracy: 0.244222, val accuracy: 0.249000\n",
      "Loss: 1.984900, Train accuracy: 0.244222, val accuracy: 0.249000\n",
      "Loss: 2.220462, Train accuracy: 0.244111, val accuracy: 0.249000\n",
      "Loss: 2.204033, Train accuracy: 0.244222, val accuracy: 0.249000\n",
      "Loss: 2.077851, Train accuracy: 0.244222, val accuracy: 0.249000\n",
      "Loss: 2.057212, Train accuracy: 0.244222, val accuracy: 0.249000\n",
      "Loss: 2.092081, Train accuracy: 0.244333, val accuracy: 0.249000\n",
      "Loss: 2.096851, Train accuracy: 0.244333, val accuracy: 0.249000\n",
      "Loss: 2.110976, Train accuracy: 0.244556, val accuracy: 0.249000\n",
      "Loss: 2.196794, Train accuracy: 0.244667, val accuracy: 0.249000\n",
      "Loss: 2.236616, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.065425, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.018329, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.157211, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.056688, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.203821, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.128052, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.228091, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.251538, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.105079, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.186904, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.214818, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.127928, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.008557, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.108280, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.094666, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.168347, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.060618, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.014416, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.183491, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.177044, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.132231, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.070397, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.990761, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.797815, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.227474, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.270829, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.168263, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.063282, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.202694, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.116688, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.035134, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.132101, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.030832, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.155367, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.058348, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.186445, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.061972, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.093487, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.188162, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.160230, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.147168, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.142432, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.057440, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.062264, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.228902, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.076209, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.191863, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.143271, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.106985, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.059431, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.144856, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.161252, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.105594, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.117047, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.229957, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.185380, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.061726, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.229885, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.132715, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.247739, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.195991, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.061506, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.226716, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.065199, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.046311, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.143309, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.184030, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.129625, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.073168, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.308612, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.959973, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.110273, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.082268, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.284678, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.147300, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.096594, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.112762, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.126579, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.042904, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.157232, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.201277, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.027683, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.003126, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.141843, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.152867, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.098573, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.012730, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.143820, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.982033, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.057440, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.255643, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.188600, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.188696, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.096557, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.061040, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.166033, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.108528, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.084863, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.075496, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.229498, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.136569, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.145199, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.184853, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.926083, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.030769, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.063624, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.261985, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.109912, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.167607, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.076076, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.217838, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.089238, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.929584, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 1.923272, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.088011, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.120690, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.022831, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.191604, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.022092, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.105912, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.102991, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.143029, Train accuracy: 0.244778, val accuracy: 0.249000\n",
      "Loss: 2.216611, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.149731, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.023563, Train accuracy: 0.210778, val accuracy: 0.218000\n",
      "Loss: 2.043673, Train accuracy: 0.266778, val accuracy: 0.274000\n",
      "Loss: 1.870558, Train accuracy: 0.356444, val accuracy: 0.361000\n",
      "Loss: 1.704361, Train accuracy: 0.409667, val accuracy: 0.413000\n",
      "Loss: 1.670939, Train accuracy: 0.466333, val accuracy: 0.464000\n",
      "Loss: 1.595116, Train accuracy: 0.522333, val accuracy: 0.526000\n",
      "Loss: 1.379669, Train accuracy: 0.557778, val accuracy: 0.547000\n",
      "Loss: 1.526808, Train accuracy: 0.589667, val accuracy: 0.569000\n",
      "Loss: 1.531233, Train accuracy: 0.612889, val accuracy: 0.594000\n",
      "Loss: 1.206691, Train accuracy: 0.640000, val accuracy: 0.618000\n",
      "Loss: 1.414440, Train accuracy: 0.651000, val accuracy: 0.636000\n",
      "Loss: 1.009892, Train accuracy: 0.664667, val accuracy: 0.640000\n",
      "Loss: 1.372987, Train accuracy: 0.670778, val accuracy: 0.652000\n",
      "Loss: 1.251759, Train accuracy: 0.676000, val accuracy: 0.667000\n",
      "Loss: 1.133146, Train accuracy: 0.692444, val accuracy: 0.674000\n",
      "Loss: 1.204354, Train accuracy: 0.694556, val accuracy: 0.675000\n",
      "Loss: 1.093903, Train accuracy: 0.705556, val accuracy: 0.688000\n",
      "Loss: 1.091817, Train accuracy: 0.705111, val accuracy: 0.682000\n",
      "Loss: 0.894199, Train accuracy: 0.709444, val accuracy: 0.686000\n",
      "Loss: 1.085172, Train accuracy: 0.714222, val accuracy: 0.695000\n",
      "Loss: 1.131306, Train accuracy: 0.718111, val accuracy: 0.701000\n",
      "Loss: 1.211550, Train accuracy: 0.721667, val accuracy: 0.699000\n",
      "Loss: 1.312673, Train accuracy: 0.723111, val accuracy: 0.702000\n",
      "Loss: 0.664610, Train accuracy: 0.728000, val accuracy: 0.712000\n",
      "Loss: 1.184304, Train accuracy: 0.730000, val accuracy: 0.703000\n",
      "Loss: 0.845623, Train accuracy: 0.731000, val accuracy: 0.705000\n",
      "Loss: 0.919108, Train accuracy: 0.731556, val accuracy: 0.708000\n",
      "Loss: 1.268651, Train accuracy: 0.732556, val accuracy: 0.708000\n",
      "Loss: 0.975283, Train accuracy: 0.735778, val accuracy: 0.704000\n",
      "Loss: 0.949979, Train accuracy: 0.739444, val accuracy: 0.709000\n",
      "Loss: 0.739746, Train accuracy: 0.738667, val accuracy: 0.711000\n",
      "Loss: 1.080581, Train accuracy: 0.740889, val accuracy: 0.712000\n",
      "Loss: 1.083869, Train accuracy: 0.737000, val accuracy: 0.711000\n",
      "Loss: 0.775478, Train accuracy: 0.741222, val accuracy: 0.719000\n",
      "Loss: 0.739056, Train accuracy: 0.740444, val accuracy: 0.719000\n",
      "Loss: 1.111133, Train accuracy: 0.744556, val accuracy: 0.712000\n",
      "Loss: 1.091988, Train accuracy: 0.746778, val accuracy: 0.713000\n",
      "Loss: 1.054228, Train accuracy: 0.745778, val accuracy: 0.711000\n",
      "Loss: 1.064693, Train accuracy: 0.747444, val accuracy: 0.716000\n",
      "Loss: 1.389543, Train accuracy: 0.747111, val accuracy: 0.718000\n",
      "Loss: 0.965390, Train accuracy: 0.749556, val accuracy: 0.716000\n",
      "Loss: 0.907465, Train accuracy: 0.748000, val accuracy: 0.715000\n",
      "Loss: 1.036351, Train accuracy: 0.749889, val accuracy: 0.713000\n",
      "Loss: 0.955271, Train accuracy: 0.750111, val accuracy: 0.712000\n",
      "Loss: 0.932538, Train accuracy: 0.750222, val accuracy: 0.711000\n",
      "Loss: 1.050328, Train accuracy: 0.751000, val accuracy: 0.710000\n",
      "Loss: 0.537069, Train accuracy: 0.750111, val accuracy: 0.715000\n",
      "Loss: 1.022207, Train accuracy: 0.750333, val accuracy: 0.711000\n",
      "Loss: 0.884778, Train accuracy: 0.751556, val accuracy: 0.717000\n",
      "Loss: 0.809186, Train accuracy: 0.751667, val accuracy: 0.711000\n",
      "Loss: 0.985478, Train accuracy: 0.750889, val accuracy: 0.712000\n",
      "Loss: 0.897694, Train accuracy: 0.751667, val accuracy: 0.715000\n",
      "Loss: 1.216667, Train accuracy: 0.751444, val accuracy: 0.718000\n",
      "Loss: 0.922066, Train accuracy: 0.752556, val accuracy: 0.714000\n",
      "Loss: 1.114016, Train accuracy: 0.753000, val accuracy: 0.713000\n",
      "Loss: 1.006380, Train accuracy: 0.753000, val accuracy: 0.714000\n",
      "Loss: 0.890662, Train accuracy: 0.751667, val accuracy: 0.714000\n",
      "Loss: 0.749620, Train accuracy: 0.753667, val accuracy: 0.715000\n",
      "Loss: 0.762079, Train accuracy: 0.752667, val accuracy: 0.718000\n",
      "Loss: 1.039657, Train accuracy: 0.752556, val accuracy: 0.714000\n",
      "Loss: 0.950166, Train accuracy: 0.752111, val accuracy: 0.716000\n",
      "Loss: 0.766425, Train accuracy: 0.753333, val accuracy: 0.717000\n",
      "Loss: 0.848101, Train accuracy: 0.752556, val accuracy: 0.717000\n",
      "Loss: 0.825833, Train accuracy: 0.753000, val accuracy: 0.716000\n",
      "Loss: 1.244636, Train accuracy: 0.752667, val accuracy: 0.717000\n",
      "Loss: 1.017989, Train accuracy: 0.753556, val accuracy: 0.716000\n",
      "Loss: 1.260759, Train accuracy: 0.753222, val accuracy: 0.720000\n",
      "Loss: 0.936712, Train accuracy: 0.753222, val accuracy: 0.718000\n",
      "Loss: 0.859438, Train accuracy: 0.753111, val accuracy: 0.715000\n",
      "Loss: 1.251273, Train accuracy: 0.752889, val accuracy: 0.715000\n",
      "Loss: 1.252934, Train accuracy: 0.753444, val accuracy: 0.716000\n",
      "Loss: 0.966093, Train accuracy: 0.753333, val accuracy: 0.716000\n",
      "Loss: 1.255601, Train accuracy: 0.753111, val accuracy: 0.715000\n",
      "Loss: 0.840739, Train accuracy: 0.753111, val accuracy: 0.720000\n",
      "Loss: 0.881845, Train accuracy: 0.753111, val accuracy: 0.719000\n",
      "Loss: 0.854494, Train accuracy: 0.753111, val accuracy: 0.720000\n",
      "Loss: 0.825163, Train accuracy: 0.753000, val accuracy: 0.718000\n",
      "Loss: 1.013028, Train accuracy: 0.753111, val accuracy: 0.717000\n",
      "Loss: 0.972342, Train accuracy: 0.753000, val accuracy: 0.718000\n",
      "Loss: 0.854030, Train accuracy: 0.752889, val accuracy: 0.718000\n",
      "Loss: 1.053280, Train accuracy: 0.753000, val accuracy: 0.718000\n",
      "Loss: 0.835249, Train accuracy: 0.753000, val accuracy: 0.720000\n",
      "Loss: 0.872270, Train accuracy: 0.753111, val accuracy: 0.719000\n",
      "Loss: 1.328540, Train accuracy: 0.753000, val accuracy: 0.719000\n",
      "Loss: 0.808768, Train accuracy: 0.753000, val accuracy: 0.721000\n",
      "Loss: 1.151158, Train accuracy: 0.753000, val accuracy: 0.718000\n",
      "Loss: 0.962845, Train accuracy: 0.753222, val accuracy: 0.718000\n",
      "Loss: 0.843798, Train accuracy: 0.753000, val accuracy: 0.720000\n",
      "Loss: 1.004629, Train accuracy: 0.753222, val accuracy: 0.718000\n",
      "Loss: 0.957079, Train accuracy: 0.753000, val accuracy: 0.718000\n",
      "Loss: 1.009286, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 0.775267, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 1.072988, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 0.774902, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 0.664009, Train accuracy: 0.753000, val accuracy: 0.719000\n",
      "Loss: 1.239923, Train accuracy: 0.753000, val accuracy: 0.719000\n",
      "Loss: 0.886245, Train accuracy: 0.753222, val accuracy: 0.718000\n",
      "Loss: 1.146475, Train accuracy: 0.753333, val accuracy: 0.718000\n",
      "Loss: 1.086510, Train accuracy: 0.753222, val accuracy: 0.718000\n",
      "Loss: 0.694002, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 0.829975, Train accuracy: 0.753111, val accuracy: 0.719000\n",
      "Loss: 0.702948, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 1.122819, Train accuracy: 0.753222, val accuracy: 0.718000\n",
      "Loss: 1.158323, Train accuracy: 0.753333, val accuracy: 0.719000\n",
      "Loss: 0.668339, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.950298, Train accuracy: 0.753222, val accuracy: 0.719000\n",
      "Loss: 0.844871, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.801269, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.921428, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.778662, Train accuracy: 0.753444, val accuracy: 0.718000\n",
      "Loss: 1.049326, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.011680, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.661238, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.157967, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.927084, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.982525, Train accuracy: 0.753444, val accuracy: 0.718000\n",
      "Loss: 0.833359, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.133693, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.020528, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.830849, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.023684, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.561357, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.962674, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.860008, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.862439, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.744427, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.950437, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.974727, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.088133, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.752530, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.915785, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.251350, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.805505, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.859897, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.124361, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.966892, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.005155, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.044593, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.081875, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.027928, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.128572, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.771066, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.605644, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.066504, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.876947, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.860745, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.984961, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.146769, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.827420, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.817997, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.807849, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.034780, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.873695, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.823962, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.001824, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.736223, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.901265, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.895994, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.772392, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.780299, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.759808, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.040417, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.018538, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.115797, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.962966, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.924385, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.755755, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.820361, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.875085, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.485249, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.032770, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.084725, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.903468, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.672577, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.947864, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.054863, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.968476, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.781986, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.941166, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.917865, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.942155, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.777406, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.887421, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.796380, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.836076, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.197499, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.711443, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.192253, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.913019, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.955887, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 1.048027, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.744518, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.969618, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.899797, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.960901, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.773286, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.868698, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 0.947209, Train accuracy: 0.753444, val accuracy: 0.719000\n",
      "Loss: 2.250346, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289081, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257823, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285441, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.346724, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296010, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.167644, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216712, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237255, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299953, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182665, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179619, Train accuracy: 0.201000, val accuracy: 0.213000\n",
      "Loss: 2.132058, Train accuracy: 0.212889, val accuracy: 0.220000\n",
      "Loss: 2.082121, Train accuracy: 0.222778, val accuracy: 0.227000\n",
      "Loss: 2.028219, Train accuracy: 0.231778, val accuracy: 0.236000\n",
      "Loss: 2.160395, Train accuracy: 0.237667, val accuracy: 0.240000\n",
      "Loss: 2.080246, Train accuracy: 0.244000, val accuracy: 0.246000\n",
      "Loss: 2.167465, Train accuracy: 0.249778, val accuracy: 0.250000\n",
      "Loss: 2.036657, Train accuracy: 0.258222, val accuracy: 0.258000\n",
      "Loss: 2.044034, Train accuracy: 0.260889, val accuracy: 0.259000\n",
      "Loss: 1.992783, Train accuracy: 0.263333, val accuracy: 0.258000\n",
      "Loss: 2.115688, Train accuracy: 0.265778, val accuracy: 0.262000\n",
      "Loss: 2.022377, Train accuracy: 0.266444, val accuracy: 0.263000\n",
      "Loss: 1.994222, Train accuracy: 0.268778, val accuracy: 0.261000\n",
      "Loss: 2.027153, Train accuracy: 0.268444, val accuracy: 0.264000\n",
      "Loss: 1.799480, Train accuracy: 0.270111, val accuracy: 0.269000\n",
      "Loss: 1.985931, Train accuracy: 0.270444, val accuracy: 0.270000\n",
      "Loss: 2.145860, Train accuracy: 0.271889, val accuracy: 0.274000\n",
      "Loss: 2.175055, Train accuracy: 0.273222, val accuracy: 0.274000\n",
      "Loss: 1.987308, Train accuracy: 0.273778, val accuracy: 0.274000\n",
      "Loss: 1.977419, Train accuracy: 0.274444, val accuracy: 0.277000\n",
      "Loss: 1.904559, Train accuracy: 0.274667, val accuracy: 0.275000\n",
      "Loss: 2.123084, Train accuracy: 0.275333, val accuracy: 0.278000\n",
      "Loss: 2.073119, Train accuracy: 0.275333, val accuracy: 0.277000\n",
      "Loss: 2.172928, Train accuracy: 0.275444, val accuracy: 0.276000\n",
      "Loss: 2.028983, Train accuracy: 0.276556, val accuracy: 0.279000\n",
      "Loss: 1.891115, Train accuracy: 0.277111, val accuracy: 0.279000\n",
      "Loss: 1.941942, Train accuracy: 0.277333, val accuracy: 0.278000\n",
      "Loss: 1.883884, Train accuracy: 0.277333, val accuracy: 0.278000\n",
      "Loss: 2.042350, Train accuracy: 0.277000, val accuracy: 0.280000\n",
      "Loss: 2.112168, Train accuracy: 0.278111, val accuracy: 0.279000\n",
      "Loss: 2.039848, Train accuracy: 0.278556, val accuracy: 0.279000\n",
      "Loss: 1.923162, Train accuracy: 0.278667, val accuracy: 0.279000\n",
      "Loss: 2.125496, Train accuracy: 0.279000, val accuracy: 0.279000\n",
      "Loss: 1.962031, Train accuracy: 0.278667, val accuracy: 0.280000\n",
      "Loss: 1.887709, Train accuracy: 0.279111, val accuracy: 0.281000\n",
      "Loss: 1.929647, Train accuracy: 0.279222, val accuracy: 0.281000\n",
      "Loss: 2.011072, Train accuracy: 0.279556, val accuracy: 0.281000\n",
      "Loss: 1.983853, Train accuracy: 0.279778, val accuracy: 0.282000\n",
      "Loss: 1.957962, Train accuracy: 0.279889, val accuracy: 0.283000\n",
      "Loss: 1.982210, Train accuracy: 0.279667, val accuracy: 0.283000\n",
      "Loss: 1.971409, Train accuracy: 0.279889, val accuracy: 0.283000\n",
      "Loss: 1.876499, Train accuracy: 0.280222, val accuracy: 0.283000\n",
      "Loss: 2.025431, Train accuracy: 0.280111, val accuracy: 0.283000\n",
      "Loss: 1.664246, Train accuracy: 0.280111, val accuracy: 0.283000\n",
      "Loss: 2.127860, Train accuracy: 0.279889, val accuracy: 0.283000\n",
      "Loss: 2.025734, Train accuracy: 0.279889, val accuracy: 0.283000\n",
      "Loss: 1.817485, Train accuracy: 0.279667, val accuracy: 0.283000\n",
      "Loss: 1.930482, Train accuracy: 0.280000, val accuracy: 0.283000\n",
      "Loss: 1.876040, Train accuracy: 0.280000, val accuracy: 0.283000\n",
      "Loss: 2.028117, Train accuracy: 0.280000, val accuracy: 0.283000\n",
      "Loss: 1.955632, Train accuracy: 0.279889, val accuracy: 0.283000\n",
      "Loss: 2.140409, Train accuracy: 0.280111, val accuracy: 0.283000\n",
      "Loss: 1.950994, Train accuracy: 0.280111, val accuracy: 0.283000\n",
      "Loss: 1.808065, Train accuracy: 0.280222, val accuracy: 0.283000\n",
      "Loss: 1.941134, Train accuracy: 0.280222, val accuracy: 0.283000\n",
      "Loss: 2.122343, Train accuracy: 0.280222, val accuracy: 0.283000\n",
      "Loss: 2.094545, Train accuracy: 0.280556, val accuracy: 0.283000\n",
      "Loss: 1.889818, Train accuracy: 0.280444, val accuracy: 0.283000\n",
      "Loss: 1.937824, Train accuracy: 0.280556, val accuracy: 0.283000\n",
      "Loss: 1.808964, Train accuracy: 0.280778, val accuracy: 0.283000\n",
      "Loss: 2.125690, Train accuracy: 0.280889, val accuracy: 0.283000\n",
      "Loss: 2.185784, Train accuracy: 0.280889, val accuracy: 0.283000\n",
      "Loss: 1.934815, Train accuracy: 0.280889, val accuracy: 0.283000\n",
      "Loss: 1.964380, Train accuracy: 0.280778, val accuracy: 0.283000\n",
      "Loss: 2.089900, Train accuracy: 0.280889, val accuracy: 0.283000\n",
      "Loss: 1.733259, Train accuracy: 0.281000, val accuracy: 0.283000\n",
      "Loss: 2.101329, Train accuracy: 0.281000, val accuracy: 0.283000\n",
      "Loss: 1.803391, Train accuracy: 0.281000, val accuracy: 0.283000\n",
      "Loss: 1.875737, Train accuracy: 0.280889, val accuracy: 0.283000\n",
      "Loss: 1.859992, Train accuracy: 0.281000, val accuracy: 0.283000\n",
      "Loss: 2.088665, Train accuracy: 0.281000, val accuracy: 0.283000\n",
      "Loss: 2.022865, Train accuracy: 0.281000, val accuracy: 0.283000\n",
      "Loss: 1.938989, Train accuracy: 0.281111, val accuracy: 0.283000\n",
      "Loss: 2.153065, Train accuracy: 0.281111, val accuracy: 0.283000\n",
      "Loss: 1.816512, Train accuracy: 0.281111, val accuracy: 0.282000\n",
      "Loss: 2.043501, Train accuracy: 0.281111, val accuracy: 0.282000\n",
      "Loss: 2.052366, Train accuracy: 0.281111, val accuracy: 0.282000\n",
      "Loss: 2.174662, Train accuracy: 0.281111, val accuracy: 0.282000\n",
      "Loss: 1.930984, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.192196, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.987598, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.862219, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.822553, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.042600, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.902693, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.150165, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.679171, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.959116, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.053085, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.998022, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.704028, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.090064, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.023703, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.080729, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.988969, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.967793, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.038470, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.007730, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.017614, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.985361, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.954641, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.993673, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.001621, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.065424, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.915411, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.152147, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.068891, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.964224, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.816819, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.784740, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.106707, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.055764, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.209848, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.157784, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.904038, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.832465, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.882289, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.184679, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.729655, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.889038, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.186221, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.075431, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.957420, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.098515, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.947841, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.979636, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.917823, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.926768, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.899847, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.774803, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.914852, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.828252, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.008741, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.009844, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.966522, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.988048, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.961583, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.966521, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.022068, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.933184, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.796950, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.799245, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.859653, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.045287, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.998208, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.845710, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.654991, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.885852, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.085714, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.056998, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.034989, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.133405, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.070219, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.067148, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.008984, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.086981, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.262475, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.766004, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.087517, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.043294, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.001581, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.942903, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.817704, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.941077, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.935410, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.973190, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.883269, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.179300, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.057975, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.938353, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.859740, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.833455, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.852580, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.970277, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.891236, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.121660, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.881598, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.986214, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.928265, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.130231, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.820453, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.158526, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.836391, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.968488, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.931201, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 2.004785, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.963440, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "Loss: 1.936554, Train accuracy: 0.281222, val accuracy: 0.282000\n",
      "best validation accuracy achieved: 0.744000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 100\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "best_loss_history = []\n",
    "best_train_history = []\n",
    "best_val_history = []\n",
    "\n",
    "for i in range(10):\n",
    "    lrate = 0.1 ** np.random.uniform(1, 3)\n",
    "    reg = 0.1 ** np.random.uniform(2, 4)\n",
    "    lrate_decay = np.random.uniform(0.8, 0.98)\n",
    "    hidden_layer_number = np.random.randint(16, 128)\n",
    "\n",
    "    model = TwoLayerNet(n_input=train_X[0].shape[0], n_output=10, hidden_layer_size=hidden_layer_number, reg=reg)\n",
    "    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "    trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=lrate, num_epochs=num_epochs, batch_size=batch_size, learning_rate_decay=lrate_decay)\n",
    "    loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "    if (np.max(val_history) > best_val_accuracy):\n",
    "        print(\"lr:\", lrate, \"; reg:\", reg, \"; hidden:\", hidden_layer_number)\n",
    "        best_classifier = model\n",
    "        best_val_accuracy = np.max(val_history)\n",
    "\n",
    "        best_loss_history = loss_history\n",
    "        best_train_history = train_history\n",
    "        best_val_history =  val_history\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc1c4e9b1f0>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(best_train_history)\n",
    "plt.plot(best_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.710000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b3e1f895e40cdda6139d18f26fe0356c7f513787d94fe727b35acf6e7b6416c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
